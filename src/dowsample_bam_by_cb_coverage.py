#!/usr/bin/env python3
import os
import pysam
import argparse
import pandas as pd
import numpy as np
from scipy.sparse import csr_matrix
from scipy.io import mmwrite

# scirpt to downsample reads per cell barcode (CB) from BAM
# scirpt is compatible BAM files generated by STARsolo

def get_cb_coverage(bamfile):
    # make dict
    cb_dict = {}
    for read in inp.fetch():
    # use primary reads
        if not read.is_supplementary and not read.is_secondary:
            cb = read.get_tag('CB')
            if cb not in cb_dict:
                cb_dict[cb] = 1
            else:
                cb_dict[cb] += 1
    return cb_dict

def downsample_by_cov(bam, out, target_num_reads, seed, threads):
    
    # index bam
    pysam.index(bam)
    
    # read bam
    inp = pysam.AlignmentFile(bam, 'rb', threads = threads)
    
    # calculate coverage of each cb
    cb_cov = get_cb_coverage(inp)

    # make dicts
    ub_set = {}
    rd_set = {}
    
    # set seed
    np.random.seed(seed)
    
    # parse bam
    for read in inp.fetch():
        # use primary reads
        if not read.is_supplementary and not read.is_secondary:
            rand_value = np.random.rand()
            # get tags
            cb = read.get_tag('CB')
            ub = read.get_tag('UB')
            gn = read.get_tag('GN')
            # downsample based on coverage
            if rand_value < (target_num_reads / cb_cov[cb]):
                if cb not in ub_sets:
                    ub_set[cb] = set([])
                    rd_set[cb] = 0
                elif rd_set[cb] >= target_num_reads:
                    ub_set[cb]
                    rd_set[cb]
                elif '-' in {ub, gn}:
                    rd_set[cb] += 1
                else:
                    ub_set[cb].add((ub, gn))
                    rd_set[cb] += 1
        
        # flatted data
        genes = set(g for genes in ub_set.values() for u, g in genes)
        ub_df = pd.DataFrame(
            data = 0,
            index = np.array(list(ub_set.keys())),
            columns = genes
        )
        
        rd_df = pd.DataFrame.from_dict(
            data = rd_set,
            orient = 'index',
            columns = ['reads']
        )

        # count umis per gene
        for barcode, genes in ub_set.items():
            if genes:
                for umi, gene in genes:
                    ub_df.loc[barcode, gene] += 1

        # create sparse matrix
        ub_mat = csr_matrix(ub_df.values)

        # write outputs
        mmwrite(
        target = out + '/ub_mat.mtx',
        a = ub_mat
        )
        ub_df.to_csv(
            path_or_buf = out + '/ub_barcodes.tsv',
            columns = [],
            header = False
        )
        ub_df.transpose().to_csv(
            path_or_buf = out + '/ub_features.tsv',
            columns = [],
            header = False
        )
        rd_df.to_csv(
            path_or_buf = out + '/reads_per_cb.tsv',
            index_label = 'barcode',
            sep = '\t'
        )

def main():
    parser = argparse.ArgumentParser(add_help=True)
    parser.add_argument(
        '--bam', type=str, metavar='FILENAME',
        help='path to input BAM file'
    )
    parser.add_argument(
        '--out', type=str, metavar='PATH',
        help='path to output directory'
    )
    parser.add_argument(
        '--target_num_reads', type=int, default = 20e3,
        help='number of reads to downsample per cell barcode'
    )
    parser.add_argument(
        '--seed', type=int, default = 0,
        help='number of threads to use'
    )
    parser.add_argument(
        '--n', type=int, default = 4,
        help='number of threads to use'
    )
    
    args = parser.parse_args()

    downsample_by_cov(
        bam = args.bam,
        out = args.out,
        target_num_reads = args.target_num_reads,
        seed = args.seed,
        threads = args.n
    )

if __name__ == "__main__":
    main()
